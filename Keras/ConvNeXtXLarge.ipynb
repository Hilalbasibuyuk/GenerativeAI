{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssNjVr1OO7gX",
        "outputId": "a84f7e50-80ce-4790-9c14-6dbbd1c0f9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_D504rRbPUmF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import ConvNeXtXLarge\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "aeMq2GKeUdOr"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/content/drive/MyDrive/Colab Notebooks/Data/train\"\n",
        "val_dir = \"/content/drive/MyDrive/Colab Notebooks/Data/valid\"\n",
        "test_dir = \"/content/drive/MyDrive/Colab Notebooks/Data/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4kG9SdG6Uqqi"
      },
      "outputs": [],
      "source": [
        "img_height, img_width = 224, 224\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Uw3EjbEvUtnD"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cS1u_uqmUwEr"
      },
      "outputs": [],
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IklboWGFbRKo",
        "outputId": "d7b55677-09ed-4207-893a-1c8ce01c5933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 613 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode = \"rgb\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkAOly4gbVoV",
        "outputId": "5b7808dd-d867-4358-df70-f0b5e76d8a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 72 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode = \"rgb\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb8yCFlhcg5S",
        "outputId": "4a3c1d04-1bd8-4e9d-f3a5-27e4b8a6f37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 315 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode = \"rgb\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3egUwXGGcjND"
      },
      "outputs": [],
      "source": [
        "base_model = ConvNeXtXLarge(weights = \"imagenet\", include_top = False, input_shape = (img_height, img_width,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "y4cfacgidRYA"
      },
      "outputs": [],
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation = \"relu\")(x)\n",
        "predictions = Dense(train_generator.num_classes, activation = \"softmax\")(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "jBfTsm2-dTa-"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iTwakGNidWX6"
      },
      "outputs": [],
      "source": [
        "for layers in base_model.layers:\n",
        "    layers.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ZoS4YA10dYhU"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = Adam(learning_rate = 0.001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YLKwPGtCdaxe"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator,\n",
        "                    steps_per_epoch = train_generator.samples//batch_size,\n",
        "                   validation_data = val_generator,\n",
        "                   validation_steps = val_generator.samples//batch_size,\n",
        "                   epochs = 50,\n",
        "                   callbacks = [checkpoint, early_stopping])"
      ],
      "metadata": {
        "id": "rwl5HgZWhvrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}