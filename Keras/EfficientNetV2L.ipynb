{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06220899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2L\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ee97d",
   "metadata": {},
   "source": [
    "# Veri yükleme ve ön işleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b1a0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'C:\\Users\\hilal\\OneDrive\\Belgeler\\GenerativeAI\\Keras\\Data\\train'\n",
    "val_dir = r'C:\\Users\\hilal\\OneDrive\\Belgeler\\GenerativeAI\\Keras\\Data\\valid'\n",
    "test_dir = r'C:\\Users\\hilal\\OneDrive\\Belgeler\\GenerativeAI\\Keras\\Data\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb90e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 224, 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95df9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02be71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22eaf58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 613 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode = \"rgb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85ff80c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode = \"rgb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50ec76e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 315 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode = \"rgb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4221c3c5",
   "metadata": {},
   "source": [
    "# Modeli oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "786e73ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-l_notop.h5\n",
      "473176280/473176280 [==============================] - 159s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = EfficientNetV2L(weights = \"imagenet\", include_top = False, input_shape = (img_height, img_width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f4c25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation = \"relu\")(x)\n",
    "predictions = Dense(train_generator.num_classes, activation = \"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5e804e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00778639",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in base_model.layers:\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b4a840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate = 0.001), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac631d",
   "metadata": {},
   "source": [
    "# Modeli eğitme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64e7ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ddac2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.3790 - accuracy: 0.2995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hilal\\anaconda3\\envs\\Hilal\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 157s 7s/step - loss: 1.3790 - accuracy: 0.2995 - val_loss: 1.3681 - val_accuracy: 0.3281\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 119s 6s/step - loss: 1.3596 - accuracy: 0.3339 - val_loss: 1.3740 - val_accuracy: 0.3281\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 94s 5s/step - loss: 1.3460 - accuracy: 0.3442 - val_loss: 1.3803 - val_accuracy: 0.4531\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 89s 5s/step - loss: 1.3380 - accuracy: 0.3569 - val_loss: 1.3311 - val_accuracy: 0.4219\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 84s 4s/step - loss: 1.3132 - accuracy: 0.4114 - val_loss: 1.3534 - val_accuracy: 0.4375\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 97s 5s/step - loss: 1.3029 - accuracy: 0.3890 - val_loss: 1.3518 - val_accuracy: 0.4375\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 100s 5s/step - loss: 1.2816 - accuracy: 0.4114 - val_loss: 1.2842 - val_accuracy: 0.4375\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 92s 5s/step - loss: 1.2561 - accuracy: 0.3907 - val_loss: 1.3678 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 88s 5s/step - loss: 1.2669 - accuracy: 0.4079 - val_loss: 1.3531 - val_accuracy: 0.3750\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 88s 5s/step - loss: 1.2428 - accuracy: 0.4079 - val_loss: 1.2630 - val_accuracy: 0.4688\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 88s 5s/step - loss: 1.2649 - accuracy: 0.4062 - val_loss: 1.2098 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 86s 5s/step - loss: 1.2341 - accuracy: 0.4269 - val_loss: 1.2142 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 86s 4s/step - loss: 1.2067 - accuracy: 0.4389 - val_loss: 1.2340 - val_accuracy: 0.4688\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 84s 4s/step - loss: 1.1850 - accuracy: 0.4458 - val_loss: 1.2318 - val_accuracy: 0.4531\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 85s 5s/step - loss: 1.1771 - accuracy: 0.4406 - val_loss: 1.1993 - val_accuracy: 0.4375\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 86s 5s/step - loss: 1.2194 - accuracy: 0.4286 - val_loss: 1.1337 - val_accuracy: 0.5312\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 85s 4s/step - loss: 1.1712 - accuracy: 0.4527 - val_loss: 1.1657 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 84s 4s/step - loss: 1.1777 - accuracy: 0.4303 - val_loss: 1.2207 - val_accuracy: 0.4844\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 85s 4s/step - loss: 1.1805 - accuracy: 0.4458 - val_loss: 1.1163 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.2082 - accuracy: 0.4309 - val_loss: 1.1176 - val_accuracy: 0.5156\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 85s 5s/step - loss: 1.1680 - accuracy: 0.4389 - val_loss: 1.1672 - val_accuracy: 0.4062\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 85s 4s/step - loss: 1.1708 - accuracy: 0.4423 - val_loss: 1.1892 - val_accuracy: 0.4688\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 85s 4s/step - loss: 1.1463 - accuracy: 0.4647 - val_loss: 1.1380 - val_accuracy: 0.4531\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 85s 4s/step - loss: 1.1658 - accuracy: 0.4509 - val_loss: 1.1255 - val_accuracy: 0.4375\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 89s 5s/step - loss: 1.1320 - accuracy: 0.4852 - val_loss: 1.1051 - val_accuracy: 0.4531\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 88s 5s/step - loss: 1.1320 - accuracy: 0.4664 - val_loss: 1.0659 - val_accuracy: 0.4688\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.1435 - accuracy: 0.5215 - val_loss: 1.0946 - val_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 86s 5s/step - loss: 1.1691 - accuracy: 0.4596 - val_loss: 1.0890 - val_accuracy: 0.4844\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 84s 4s/step - loss: 1.1489 - accuracy: 0.4699 - val_loss: 1.1302 - val_accuracy: 0.4844\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 85s 4s/step - loss: 1.1371 - accuracy: 0.4854 - val_loss: 1.1472 - val_accuracy: 0.4531\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 86s 5s/step - loss: 1.1347 - accuracy: 0.4630 - val_loss: 1.0436 - val_accuracy: 0.5625\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 86s 5s/step - loss: 1.1089 - accuracy: 0.4337 - val_loss: 1.1300 - val_accuracy: 0.4531\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.1106 - accuracy: 0.4836 - val_loss: 1.0746 - val_accuracy: 0.5156\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 88s 5s/step - loss: 1.1251 - accuracy: 0.5009 - val_loss: 1.0369 - val_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.1159 - accuracy: 0.4819 - val_loss: 1.1231 - val_accuracy: 0.4219\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.0928 - accuracy: 0.5146 - val_loss: 1.0924 - val_accuracy: 0.5469\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 90s 5s/step - loss: 1.1221 - accuracy: 0.4605 - val_loss: 1.0968 - val_accuracy: 0.5156\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.1182 - accuracy: 0.4733 - val_loss: 1.1036 - val_accuracy: 0.4688\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.0773 - accuracy: 0.4991 - val_loss: 1.1134 - val_accuracy: 0.5156\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.1024 - accuracy: 0.4733 - val_loss: 1.0613 - val_accuracy: 0.4531\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.0901 - accuracy: 0.5077 - val_loss: 1.0446 - val_accuracy: 0.4688\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 86s 5s/step - loss: 1.1048 - accuracy: 0.4957 - val_loss: 1.0617 - val_accuracy: 0.4531\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 85s 4s/step - loss: 1.0889 - accuracy: 0.4940 - val_loss: 1.0903 - val_accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 85s 4s/step - loss: 1.0822 - accuracy: 0.5181 - val_loss: 1.0802 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch = train_generator.samples//batch_size,\n",
    "                   validation_data = val_generator,\n",
    "                   validation_steps = val_generator.samples//batch_size,\n",
    "                   epochs = 50,\n",
    "                   callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321df22",
   "metadata": {},
   "source": [
    "# Modeli değerlendirme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a09152",
   "metadata": {},
   "source": [
    "### En iyi modeli yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1beced7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd793e1",
   "metadata": {},
   "source": [
    "### Test seti üzerinde değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de6e6343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 37s 4s/step - loss: 1.6298 - accuracy: 0.2465\n",
      "Test accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test accuracy: {test_acc:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
